# Utilizing Logistic Regression in TensorFlow
# We begin by installing TensorFlow version 2.9.0 and its required prerequistes.

!pip install grpcio==1.24.3
!pip install tensorflow==2.9.0
!pip install --upgrade scikit-learn numpy

# For us to utilize Logistic Regression in TensorFlow, we first need to import the required libraries. For importing those libraries,

import tensorflow as tf
import pandas as pd
import numpy as np
import time
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Here we work with Iris dataset for understing logistic regression

iris = load_iris()
iris_X, iris_y = iris.data[:-1,:], iris.target[:-1]
iris_y= pd.get_dummies(iris_y).values
trainX, testX, trainY, testY = train_test_split(iris_X, iris_y, test_size=0.33, random_state=42)

# Now we define x and y. These variables will hold our iris data (both the features and label matrices) 
# We also need to give them shapes which correspond to the shape of our data.

numFeatures = trainX.shape[1]
print('numFeatures is : ', numFeatures )
numLabels = trainY.shape[1]
print('numLabels is : ', numLabels )

trainX = tf.constant(trainX, dtype='float32')
trainY = tf.constant(trainY, dtype='float32')
testX = tf.constant(testX, dtype='float32')
testY = tf.constant(testY, dtype='float32')

# Now, We define two TensorFlow variables as our parameters.
# These variables will hold the weights and biases of our logistic regression and they will be continually updated during training.

W = tf.Variable(tf.zeros([4, 3]))
b = tf.Variable(tf.zeros([3]))

weights = tf.Variable(tf.random.normal([numFeatures,numLabels],mean=0.,stddev=0.01,name="weights"),dtype='float32')
bias = tf.Variable(tf.random.normal([1,numLabels],mean=0.,stddev=0.01,name="bias"))

# We now define our operations in order to properly run the Logistic Regression. 
# Logistic regression is typically thought of as a single equation:

# Å·=ð‘ ð‘–ð‘”ð‘šð‘œð‘–ð‘‘(ð‘Šð‘‹+ð‘)

def logistic_regression(x):
    apply_weights_OP = tf.matmul(x, weights, name="apply_weights")
    add_bias_OP = tf.add(apply_weights_OP, bias, name="add_bias") 
    activation_OP = tf.nn.sigmoid(add_bias_OP, name="activation")
    return activation_OP

# learning rate
# Number of Epochs in our training
numEpochs = 700

# Defining our learning rate iterations (decay)
learningRate = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.0008,
                                          decay_steps=trainX.shape[0],
                                          decay_rate= 0.95,
                                          staircase=True)

#Defining our cost function - Squared Mean Error
loss_object = tf.keras.losses.MeanSquaredLogarithmicError()
optimizer = tf.keras.optimizers.SGD(learningRate)

# Accuracy metric.
def accuracy(y_pred, y_true):
# Predicted class is the index of the highest score in prediction vector (i.e. argmax).

    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))

    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

# Optimization process. 

def run_optimization(x, y):
    with tf.GradientTape() as g:
        pred = logistic_regression(x)
        loss = loss_object(pred, y)
    gradients = g.gradient(loss, [weights, bias])
    optimizer.apply_gradients(zip(gradients, [weights, bias]))

# Now we can define and run the actual training loop, like this:

# Initialize reporting variables
display_step = 10
epoch_values = []
accuracy_values = []
loss_values = []
loss = 0
diff = 1
# Training epochs
for i in range(numEpochs):
    if i > 1 and diff < .0001:
        print("change in loss %g; convergence."%diff)
        break
    else:
        # Run training step
        run_optimization(trainX, trainY)
        
        # Report occasional stats
        if i % display_step == 0:
            # Add epoch to epoch_values
            epoch_values.append(i)
            
            pred = logistic_regression(testX)

            newLoss = loss_object(pred, testY)
            # Add loss to live graphing variable
            loss_values.append(newLoss)
            
            # Generate accuracy stats on test data
            acc = accuracy(pred, testY)
            accuracy_values.append(acc)
            
            # Re-assign values for variables
            diff = abs(newLoss - loss)
            loss = newLoss

            #generate print statements
            print("step %d, training accuracy %g, loss %g, change in loss %g"%(i, acc, newLoss, diff))

# How well do we perform on held-out test data?
print("final accuracy on test set: %s" %acc.numpy())

# Plotting the above data for visualization

%matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.plot(loss_values)
plt.show()
